# Representational Complexity
## Complexity Analysis as Proof

Complexity is taught and discussed as a method of evaluating algorithms, data
structures, and more generally programs. However, complexity can be used more
generally to reason about the behaviour of any objects that have a complexity
associated with them. Not only can we use them to compare approaches, we can
also use them to prove and reason about properties of the thing that has the
complexity.

### Complexity of Integers

Take for example positive integers. As they increase in size, by how much does
the spatial complexity of the number increase? For base 10, all numbers lower
than 10 require a single digit, numbers lower than 100 require 2, etc. This
means we can take the log base 10 of the actual value and know how many digits
required to represent that value in base 10. This obviously applies across
other bases, and we can say that the spatial complexity for an integer n is on the
order O(log(n)).

Importantly, this is specifically the _upper_ bound for the representation of
an integer - there are some exceptions which we can
represent in a much more compressed form. Powers of 2 can all be represented as
the exponent of 2 that they are, so that 4294967296 can be represented as 2 ^
32, requiring a complexity of log(log2(n)).

TODO Show that the below is true by using base 2, in the same way as MIU system

It
should be clear that the upper bound for the general case cannot be
lower than O(log(n)), even though we can apply our compression to a subset of
the integers. There will always be numbers that require the full upper bound
in order to be represented, and where we need to be at least as specific as the
base 10 representation.

### Complexity-based Proof for Infinite Primes

- Fundamental shift from thinking about complexity as a way of analysing a data
structure or function to thinking about it as a property we can leverage
- In other words, if we can find two representations that are equivalent (can
represent the same set), we can do more than compare, we can make statements

- Let's expand our power of 2 example to not just 2 multiplied to itself, but
primes multiplied together (this is prime factorisation)
- Has the same form as power of 2, but with many primes
- But this time we can represent all the value we can using a number base
- Therefore, our representation as primes must also have an upper bound of O(log(n))

- Many beautiful proofs that there are infinite primes
- Chaitin showed you can use complexity to make statements about this too
- Consider if there were only finitely many primes - once our numbers get large
enough, and we run out of new primes to multiply, our prime factors
representation starts growing much more slowly, even though our digits
representation is still increasing at the same rate
- Saying there are finitely many primes is akin to saying the only prime is 2 -
with O(k.log(log(n))) with k as the number of primes.

The reason I like this proof is because it presents a deeper way of thinking
about complexity, not just as a way of comparing the expected cost of a data
structure of algorithm in computation, but as a powerful property we can use
to formally reason about things in a familiar setting.
